import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from ydata_profiling import ProfileReport
from sklearn.calibration import cross_val_predict
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import KBinsDiscretizer
import joblib
from model_With_Threshold import ModelWithThreshold
from pathlib import Path
### Mes fonctions ###

# Cr√©e une colonne indiquant si la personne a des √©tudes en ad√©quation avec son d√©partement
from sklearn.metrics import classification_report, f1_score, precision_recall_curve


def definir_match_etudes_poste(row):
    """
    Retourne 1 si les √©tudes correspondent au d√©partement, 0 sinon.
    """
    etudes = row['domaine_etude']
    dept = row['departement']
    
    # 1. Dictionnaire de correspondance (Etudes -> D√©partements acceptables)
    mapping_logique = {
        # Les Techs vont au Consulting
        'Infra & Cloud': ['Consulting'],
        'Transformation Digitale': ['Consulting'],
        
        # Les Business vont au Commercial
        'Marketing': ['Commercial'],
        'Entrepreunariat': ['Commercial'],
        
        # Les RH vont aux RH
        'Ressources Humaines': ['Ressources Humaines']
    }
    
    # 2. Gestion du cas "Autre" ( On consid√®re que c'est pas OK)
    if etudes == 'Autre':
        return 0

    # 3. V√©rification standard
    # On regarde si le d√©partement actuel est dans la liste autoris√©e pour ces √©tudes
    if etudes in mapping_logique:
        if dept in mapping_logique[etudes]:
            return 1 # C'est un Match
        else:
            return 0 # C'est un Mismatch (ex: Marketing -> Consulting)
            
    # S√©curit√© pour les cas impr√©vus
    return 0

def find_optimal_threshold(y_true, y_probas):
    """
    Trouve et affiche le meilleur seuil √† partir des probabilit√©s d√©j√† calcul√©es.
    """
    # 1. Calculer P, R et Thresholds
    precision, recall, thresholds = precision_recall_curve(y_true, y_probas)
    
    # 2. Calculer F1 pour chaque seuil
    numerator = 2 * recall * precision
    denominator = recall + precision
    
    # Gestion de la division par z√©ro
    f1_scores = np.divide(numerator, denominator, out=np.zeros_like(denominator), where=denominator!=0)
    
    # On aligne les tailles (P et R ont un √©l√©ment de plus que thresholds)
    f1_scores = f1_scores[:-1] 
    precision = precision[:-1]
    recall = recall[:-1]
    
    # 3. Trouver l'optimum
    best_idx = np.argmax(f1_scores)
    best_thresh = thresholds[best_idx]
    best_f1 = f1_scores[best_idx]
    
    print(f"Seuil optimal trouv√© : {best_thresh:.4f} avec F1-score = {best_f1:.4f}, Pr√©cision = {precision[best_idx]:.4f}, Rappel = {recall[best_idx]:.4f}")
    
    return best_thresh

from sklearn.base import BaseEstimator, TransformerMixin

class SalaryFeatureEngineering(BaseEstimator, TransformerMixin):
    """
    Transformateur personnalis√© pour √©valuer la comp√©titivit√© du salaire.
    
    Objectif :
    Comparer le salaire d'un employ√© par rapport √† ses pairs (groupe d√©fini par d√©faut 
    sur 'poste' et 'niveau_education') pour d√©terminer s'il est sous-pay√© ou sur-pay√©.
    
    Logique :
    1. Calcule la moyenne et l'√©cart-type du salaire pour chaque groupe.
    2. Calcule le Z-Score : (Salaire - Moyenne du groupe) / Ecart-type du groupe.
    3. Discr√©tise en 'score_competitivite' : 
       -1 (sous-pay√©), 0 (normal), 1 (bien pay√©) selon le seuil (threshold_std).
       
    Nettoyage sp√©cifique (Hardcoded) :
    - Supprime 'niveau_education' apr√®s le calcul (feature selection int√©gr√©e).
    - Conserve 'poste'.
    """

    def __init__(self, group_cols=['poste', 'niveau_education'], 
                 target_col='revenu_mensuel', 
                 drop_original=True,
                 drop_reference=True,
                 threshold_std=1.0): 
        
        self.group_cols = group_cols
        self.target_col = target_col
        self.drop_original = drop_original
        self.drop_reference = drop_reference
        self.threshold_std = threshold_std
        
        self.group_stats_ = None
        self.global_stats_ = {}
        self.feature_names_in_ = None

    def fit(self, X, y=None):
        X = X.copy()
        if hasattr(X, 'columns'):
            self.feature_names_in_ = list(X.columns)
        else:
            self.feature_names_in_ = [f"x{i}" for i in range(X.shape[1])]

        # 1. Stats globales
        self.global_stats_['mean'] = X[self.target_col].mean()
        self.global_stats_['std'] = X[self.target_col].std()
        self.global_stats_['median'] = X[self.target_col].median()

        # 2. Stats par groupe
        self.group_stats_ = X.groupby(self.group_cols)[self.target_col].agg(['mean', 'std', 'median'])
        self.group_stats_['std'] = self.group_stats_['std'].fillna(1.0).replace(0, 1.0)
        
        return self

    def transform(self, X):
        X = X.copy()
        
        # # 1. Join
        # X = X.join(self.group_stats_, on=self.group_cols)

        X = pd.merge(
            X, 
            self.group_stats_, 
            left_on=self.group_cols, 
            right_index=True, 
            how='left'
        )
        
        # 2. Remplissage
        X['mean'] = X['mean'].fillna(self.global_stats_['mean'])
        X['std'] = X['std'].fillna(self.global_stats_['std'])
        X['median'] = X['median'].fillna(self.global_stats_['median'])
        
        X['salaire_median_ref'] = X['median']
        
        # 3. Calcul Z-Score
        X['z_score_salaire'] = (X[self.target_col] - X['mean']) / X['std']
        
        # 4. Discr√©tisation
        X['score_competitivite'] = 0
        X.loc[X['z_score_salaire'] < -self.threshold_std, 'score_competitivite'] = -1
        X.loc[X['z_score_salaire'] > self.threshold_std, 'score_competitivite'] = 1
        
        # 5. NETTOYAGE
        cols_to_drop = ['mean', 'std', 'median', 'z_score_salaire']
        
        if self.drop_original:
            cols_to_drop.append(self.target_col)
        if self.drop_reference:
            cols_to_drop.append('salaire_median_ref')
            
        # --- C'EST ICI QUE VOUS FAITES VOTRE BRICOLAGE PROPREMENT ---
        # On supprime TOUJOURS 'niveau_education' car on a d√©cid√© qu'il √©tait inutile
        if 'niveau_education' in X.columns:
            cols_to_drop.append('niveau_education')
        # if 'poste' in X.columns:
        #     cols_to_drop.append('poste')  
        # Par contre, ON NE TOUCHE PAS √† 'poste', on le laisse passer !
            
        X = X.drop(columns=cols_to_drop, errors='ignore')
            
        return X

    def get_feature_names_out(self, input_features=None):
        if input_features is None:
            input_features = self.feature_names_in_
        feature_names = list(input_features)
        
        # 1. Suppression target
        if self.drop_original and self.target_col in feature_names:
            feature_names.remove(self.target_col)
            
        # 2. Suppression explicite de niveau_education (SYNCHRONISATION !)
        if 'niveau_education' in feature_names:
            feature_names.remove('niveau_education')

        # 3. Suppression m√©diane (si demand√©)
        if not self.drop_reference:
            feature_names.append('salaire_median_ref')
            
        # 4. Ajout du score
        feature_names.append('score_competitivite')
        
        return np.array(feature_names, dtype=object)
    

### Classes permettant de r√©aliser le feature engineering dans des pipelines ###

class DataCleaningTransformer(BaseEstimator, TransformerMixin):
    """
    S'occupe du nettoyage initial et du typage.
    """
    def fit(self, X, y=None):
        return self # Rien √† apprendre ici

    def transform(self, X):
        X = X.copy() # Toujours copier pour ne pas toucher aux donn√©es originales
        
        # Correction augmentation salaire
        if 'augementation_salaire_precedente' in X.columns:
            # On v√©rifie si c'est string avant de replace, au cas o√π des donn√©es propres arrivent
            if X['augementation_salaire_precedente'].dtype == 'object':
                X['augementation_salaire_precedente'] = X['augementation_salaire_precedente'].str.replace('%', '').astype(int)

        # Mappings binaires
        mappings = {'Oui': 1, 'Non': 0}
        
        # Heures supp
        if 'heure_supplementaires' in X.columns:
            X['heure_supplementaires'] = X['heure_supplementaires'].map(mappings)
            # Gestion des NaN √©ventuels si une valeur inconnue arrive
            X['heure_supplementaires'] = X['heure_supplementaires'].fillna(0) 

        # Genre
        if 'genre' in X.columns:
            X['genre'] = X['genre'].map({'M': 0, 'F': 1})
            
        return X

class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):
    """
    Cr√©e les nouvelles variables m√©tier.
    """
    def __init__(self, grosse_distance_threshold=17):
        # On met le seuil en param√®tre : cela permet de le changer 
        # ou de le "GridSearcher" plus tard !
        self.grosse_distance_threshold = grosse_distance_threshold

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        
        # 1. Ratio Stagnation Entreprise
        # On s√©curise pour √©viter la division par z√©ro
        X['Ratio_Stagnation_entreprise'] = np.where(
            X['annees_dans_l_entreprise'] == 0, 
            0, 
            X['annees_depuis_la_derniere_promotion'] / X['annees_dans_l_entreprise']
        )

        # 2. Match Etudes (Assure-toi que la fonction est accessible)
        X['match_etudes_poste'] = X.apply(definir_match_etudes_poste, axis=1)
        # NOTE : Si cette fonction est lente, il faudra l'optimiser, mais gardons-la pour l'instant.

        # 3. Dur√©e moyenne par poste
        X['duree_moyenne_par_poste'] = X['annee_experience_totale'] / (X['nombre_experiences_precedentes'] + 1)

        # 4. Habite loin (utilise le param√®tre de la classe)
        X['habite_loin'] = (X['distance_domicile_travail'] > self.grosse_distance_threshold).astype(int)

        # 5. Ratio Stagnation Poste
        X['ratio_stagnation_poste'] = X['annees_dans_le_poste_actuel'] / (X['annees_dans_l_entreprise'] + 1)

        # 6. Nouveau Responsable
        X['nouveau_responsable'] = (X['annes_sous_responsable_actuel'] < 2).astype(int)

        # 7. Ratio Gain Effort
        # Attention : s'assurer que heure_supplementaires est bien num√©rique (fait dans l'√©tape d'avant)
        X['Ratio_Gain_Effort'] = X['revenu_mensuel'] / (1 + X['heure_supplementaires'])

        return X

class ColumnDropperTransformer(BaseEstimator, TransformerMixin):
    """
    Supprime les colonnes inutiles apr√®s le feature engineering.
    """
    def __init__(self, columns_to_drop=None):
        if columns_to_drop is None:
            self.columns_to_drop = [
                'domaine_etude',
                'annees_depuis_la_derniere_promotion',
                'nombre_experiences_precedentes',
                'annees_dans_l_entreprise',
                'annees_dans_le_poste_actuel',
                'distance_domicile_travail',
                'annes_sous_responsable_actuel',
                'departement',
                'annee_experience_totale'
            ]
        else:
            self.columns_to_drop = columns_to_drop

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        # On ne drop que les colonnes qui existent r√©ellement dans X
        # (Pour √©viter les erreurs si on relance le script deux fois)
        cols_existing = [c for c in self.columns_to_drop if c in X.columns]
        return X.drop(columns=cols_existing)

###################################################################
###         """ Partie principale du script """                 ###
###################################################################

# on r√©cup√®re les diff√©rents r√©pertoires
current_dir = Path(__file__).resolve().parent
project_root = current_dir.parent
models_dir = project_root / "models"
artifacts_dir = project_root / "artifacts"

### Chargement des donn√©es ###
    
df_eval = pd.read_csv(project_root / "data/extrait_eval.csv")
df_sirh = pd.read_csv(project_root / "data/extrait_sirh.csv")
df_sondage = pd.read_csv(project_root / "data/extrait_sondage.csv")

### Fusion et nettoyage des datasets ###

df_eval['eval_number'] = df_eval['eval_number'].str.lower().str.replace('e_', '').astype(int)

df_final = (
    df_eval
    .merge(df_sirh, left_on='eval_number', right_on='id_employee')  # Jointure 1
    .drop(columns=['id_employee'])                     # Nettoyage 1
    .merge(df_sondage, left_on='eval_number', right_on='code_sondage')   # Jointure 2 (on r√©utilise 'id' qui vient de df1)
    .drop(columns=['code_sondage'])                      # Nettoyage 2
)

# ont uniquement la valeur 1, partout donc on enl√®ve
df_clean = df_final.drop(columns=["nombre_employee_sous_responsabilite","ayant_enfants"])
# n'a que la valeur 80 donc on enl√®ve √©galement
df_clean = df_clean.drop(columns="nombre_heures_travailless")
# on enl√®ve √©galement les id
df_clean = df_clean.drop(columns="eval_number")


# on supprime les colonnes trop corr√©l√©es d'apr√®s le profiling g√©n√©r√© auparavant
df_clean = df_clean.drop(columns=['age', 'note_evaluation_actuelle','niveau_hierarchique_poste'])


profile = ProfileReport(df_clean, title="Rapport d'Exploration du data frame final")
profile.to_file(artifacts_dir / "rapport_final.html")

# 1. Pr√©paration du train test


X = df_clean.drop(columns=['a_quitte_l_entreprise'])
y = df_clean['a_quitte_l_entreprise'].map({'Oui': 1, 'Non': 0})

# 2. Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


#colonnes √† one-hot encoder (pour post il faut le faire avant le salary feature engineering)
cols_a_encoder = ['frequence_deplacement', 'statut_marital','poste']
# cols_target = ['poste']

# handle_unknown='ignore' √©vite les crashs si une nouvelle cat√©gorie apparait
encodage = ColumnTransformer(
    transformers=[
        ('one_hot', OneHotEncoder(drop='first', handle_unknown='ignore'), cols_a_encoder),


        # La discr√©tisation pour le ratio (Binning)
        # strategy='quantile' cr√©e des groupes de taille √©gale
        # n_bins=5 cr√©e 5 niveaux (Tr√®s faible, Faible, Moyen, √âlev√©, Tr√®s √©lev√©)
        ('binning_ratio', KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile'),
          ['ratio_stagnation_poste'])
    ],
    remainder='passthrough', # IMPORTANT : on garde les autres colonnes (num√©riques) telles quelles
    verbose_feature_names_out=False # pour √©viter d'avoir "remainder_" devant le nom de nos colonnes
)

salaryFE = SalaryFeatureEngineering(
        group_cols=['poste','niveau_education'],
        target_col='revenu_mensuel',
        drop_original=True,  # On supprime la colonne salaire_mensuel originale car corr√©l√©e
        drop_reference=True, # On ne garde pas la colonne de r√©f√©rence m√©diane
        threshold_std=1      # Seuil pour la discr√©tisation
    )

rf_cw = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    class_weight='balanced_subsample',  # Gestion dynamique du d√©s√©quilibre
    min_samples_leaf=5,                 # Emp√™che l'overfitting sur les poids √©lev√©s
    max_depth=10                        # (Optionnel) Limite la complexit√©
)

# Cr√©ation de la pipeline de feature ing√©nierie
pipeline_preprocessing = Pipeline([
    ('cleaning', DataCleaningTransformer()),
    ('feature_engineering', FeatureEngineeringTransformer(grosse_distance_threshold=17)),
    ('dropping', ColumnDropperTransformer())
])

full_pipeline = Pipeline([
    # Avant de one-hot encoder les colonnes cat√©gorielles
    ('preprocessing', pipeline_preprocessing),

    ('salary_ref', salaryFE),
    
    # one-hot encoding
    ('encoder', encodage),

    # notre mod√®le
    ('model', rf_cw) 
])

### Recherche d'hyperparam√®tres pour le mod√®le sans imblearn ###

# 1. D√©finir la grille des param√®tres √† tester
param_grid = {
    'model__n_estimators': [100, 200],
    'model__max_depth': [5, 10, 20, None],
    
    # Important avec class_weight : on √©vite 1 pour r√©duire l'overfitting sur les cas isol√©s
    'model__min_samples_leaf': [2, 4, 6],  
    
    # C'est ici qu'on teste les deux strat√©gies de gestion du d√©s√©quilibre
    'model__class_weight': ['balanced', 'balanced_subsample'] 
}

# 2. Initialiser le GridSearch

scoring_method = 'average_precision' 

# utilisation de la validation crois√©e stratifi√©e car la target est d√©s√©quilibr√©e
# D√©finition de la validation crois√©e stratifi√©e
cv_strat = StratifiedKFold(
    n_splits=5,        # Nombre de plis (folds)
    shuffle=True,      # M√©langer les donn√©es avant de diviser
    random_state=42    # Pour la reproductibilit√©
)

grid_search = GridSearchCV(
    estimator=full_pipeline,
    param_grid=param_grid,
    
    # Choix de la m√©trique
    scoring=scoring_method, 
    
    cv=cv_strat,      
    n_jobs=-1,
    verbose=1
)

# 3. Lancer la recherche
print("Recherche des meilleurs hyperparam√®tres (Mode Class Weight)...")
grid_search.fit(X_train, y_train)

# 4. R√©sultats
print(f"\nMeilleurs param√®tres trouv√©s : {grid_search.best_params_}")
print(f"Meilleur score (CV) : {grid_search.best_score_:.4f}")

# On r√©cup√®re le champion
best_model = grid_search.best_estimator_

y_probas_train_cv = cross_val_predict(best_model, X_train, y_train, cv=cv_strat, method='predict_proba')[:, 1]

# 2. Trouver le seuil optimal sur ces probabilit√©s d'entra√Ænement
best_threshold = find_optimal_threshold(y_train, y_probas_train_cv)

print(f"Le seuil √† utiliser en production est : {best_threshold}")

# --- √Ä ce stade, le mod√®le est calibr√©. On passe au TEST ---

# 3. Calculer les probabilit√©s sur le TEST
y_probas_test = best_model.predict_proba(X_test)[:, 1]

# 4. Appliquer le seuil trouv√© pr√©c√©demment pour cr√©er les pr√©dictions finales
y_pred_test_optimized = (y_probas_test >= best_threshold).astype(int)

f1_final = f1_score(y_test, y_pred_test_optimized)
print(f"üéØ F1 Score Final (Test) : {f1_final:.4f}")

# 2. Afficher le rapport complet (Pr√©cision, Rappel, Support)
# C'est tr√®s utile pour voir si ton mod√®le privil√©gie trop une classe
print("\nüìä Rapport de Classification :")
print(classification_report(y_test, y_pred_test_optimized))

# 2. Cr√©er l'objet final
final_model = ModelWithThreshold(best_model, best_threshold)

#On sauvegarde le mod√®le
save_path = models_dir / "model.pkl"
joblib.dump(final_model, save_path)

print(f"Mod√®le sauvegard√© avec succ√®s dans : {save_path}")